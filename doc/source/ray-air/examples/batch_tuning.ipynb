{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f5c2fbd-31d7-4262-94c8-1f6cea6f5938",
   "metadata": {},
   "source": [
    "# Batch training & tuning on Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ca5cc-6337-4569-b508-3784b3b6ab0c",
   "metadata": {},
   "source": [
    "Batch training and tuning are common tasks in simple machine learning use-cases such as time series forecasting. They require fitting of simple models on multiple data batches corresponding to locations, products, etc.\n",
    "\n",
    "In the context of this notebook, batch training is understood as creating the same model(s) for different and separate data, or subsets of a dataset. This notebook showcases how to conduct batch training using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).\n",
    "\n",
    "![Batch training diagram](../../data/examples/images/batch-training.svg)\n",
    "\n",
    "For the data, we will use the [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This popular tabular dataset contains historical taxi pickups by timestamp and location in NYC. To demonstrate batch training, we will simplify the data to a regression problem to predict `trip_duration` and use scikit-learn.\n",
    "\n",
    "To demonstrate how batch training can be parallelized, we will train a separate model for each dropoff location. This means we can use the `dropoff_location_id` column in the dataset to group the dataset into data batches. Then we will fit a separate model for each batch and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb02a92-a603-48b8-a23e-887ecaaf5470",
   "metadata": {},
   "source": [
    "# Introduction to Ray Tune\n",
    "\n",
    "> **While Tune's main purpose is hyperparameter optimization, you can also use it as an execution engine to manage multiple independent compute workers.**  \n",
    "\n",
    "In this notebook, we will use [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) to run separate, parallel training jobs, each as a different experiment, per dropoff location.  After all the Tune experiments have run, we will pick the best model per dropoff location.  \n",
    "\n",
    "Let us quickly walk through the [key concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) you need to know to use Tune.\n",
    "\n",
    "- First, you define a `Search space` and pass that into a `Trainable` or `callable` function, that specifies the objective you want to tune.  The trainable function will be called for every experiment in the search space.\n",
    "\n",
    "- Then you select a `Search algorithm` and optionally use a\n",
    "scheduler to stop searches early and speed up your experiments.  We will use simple **grid search** (run every permutation as a separate trial) as our search algorithm in this tutorial.\n",
    "\n",
    "- Together with other configurations, the Trainable, Search algorithm, and Scheduler are passed into `Tuner`, which runs your experiments in parallel.\n",
    "\n",
    "- The output from `Tuner.fit()` can be analyzed to inspect your experiment results.  The following figure shows an overview of the Ray Tune flow, which we will use in this tutorial.\n",
    "\n",
    "![Tune flow diagram](../../tune/images/tune_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaee275-9cb1-4fa9-9393-a04a6fe00d84",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "In this this tutorial, you will learn about:\n",
    " 1. [Define how to load and prepare Parquet data](#load_data)\n",
    " 2. [Define your Ray Tune Search Space and Search Algorithm](#define_search_space)\n",
    " 3. [Define a Trainable (callable) function](#define_trainable)\n",
    " 4. [Run independent experiments in Parallel using Ray AIR Tune](#run_tune_search)\n",
    " 5. [Load a model from checkpoint and perform inference](#load_checkpoint)\n",
    "\n",
    "# Walkthrough\n",
    "\n",
    "Let us start by importing a few required libraries, including open-source [Ray](https://github.com/ray-project/ray) itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ec7c35-5810-460c-9cf9-5cd7b62eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 8\n",
      "pyarrow: 6.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f'Number of CPUs in this system: {os.cpu_count()}')\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pds\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba8f73a-e47f-469d-a116-31fc5da8ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:17:36,892\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-09_11-17-34_825866_27490/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-09_11-17-34_825866_27490/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-11-09_11-17-34_825866_27490', 'metrics_export_port': 64093, 'gcs_address': '127.0.0.1:62719', 'address': '127.0.0.1:62719', 'dashboard_agent_listen_port': 52365, 'node_id': 'f047796bbbc91fada43c063b5df319a587610c12949637c3ea701b81'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54a9528-defe-4102-a179-d779f0dc2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPU': 8.0, 'node:127.0.0.1': 1.0, 'object_store_memory': 2147483648.0, 'memory': 8644909466.0}\n"
     ]
    }
   ],
   "source": [
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86a93c-cea6-4dbc-aebc-9a1623734d3d",
   "metadata": {},
   "source": [
    "<b>Scikit-Learn</b> is one of the most widely used tools in the ML community for working with data, offering dozens of easy-to-use machine learning algorithms. \n",
    "> However, to achieve high performance, you often need to perform model selection and checkpointing. \n",
    "\n",
    "[Train-sklearn libraries](https://docs.ray.io/en/latest/tune/examples/tune-sklearn.html) make these tasks more convenient in a distributed setting.  Below, we import sklearn, ray Tune and AIR, and our custom Train-sklearn libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd4b4a0-bcc8-49c3-8b5e-2590f9100a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# import standard sklearn libraries\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f\"sklearn: {sklearn.__version__}\")\n",
    "\n",
    "# import ray libraries\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.train.sklearn import SklearnCheckpoint\n",
    "from ray.train.sklearn import SklearnPredictor\n",
    "\n",
    "# set global random seed for sklearn models\n",
    "np.random.seed(415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0af2c6-7c90-42bc-8687-3c9b2dc9a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For benchmarking purposes, we can print the times of various operations.\n",
    "# In order to reduce clutter in the output, this is set to False by default.\n",
    "PRINT_TIMES = False\n",
    "\n",
    "def print_time(msg: str):\n",
    "    if PRINT_TIMES:\n",
    "        print(msg)\n",
    "        \n",
    "# To speed things up, weâ€™ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d69835-0104-4a89-8418-b1986e45a15c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define how to load and prepare Parquet data <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558f234-b7af-489d-8aaa-42a7c49f2194",
   "metadata": {},
   "source": [
    "First, we need to load some data.  Since the NYC Taxi dataset is fairly large, we will filter files first into a PyArrow dataset. And then in the next cell after, we will filter the data on read into a PyArrow table and convert that to a pandas dataframe.\n",
    "\n",
    "```{tip}\n",
    "Use PyArrow dataset and table for reading or writing large parquet files, since its native multithreaded C++ adpater is faster than pandas read_parquet, even using engine=pyarrow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5076160a-07c5-4ceb-83d6-22c14d3d05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Taxi using 1 file(s)!\n",
      "s3_files: ['s3://air-example-data/ursa-labs-taxi-data/by_year/2019/06/data.parquet/ab5b9d2b8cc94be19346e260b543ec35_000000.parquet']\n",
      "Locations: [145, 166, 152]\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "target = \"trip_duration\"\n",
    "s3_partitions = pds.dataset(\n",
    "    \"s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/\",\n",
    "    partitioning=[\"year\", \"month\"],\n",
    ")\n",
    "s3_files = [f\"s3://{file}\" for file in s3_partitions.files]\n",
    "\n",
    "# Obtain all location IDs\n",
    "all_location_ids = (\n",
    "    pq.read_table(s3_files[0], columns=[\"dropoff_location_id\"])[\"dropoff_location_id\"]\n",
    "    .unique()\n",
    "    .to_pylist()\n",
    ")\n",
    "\n",
    "# Use smoke testing or not.\n",
    "starting_idx = -1 if SMOKE_TEST else 0\n",
    "sample_locations = [145, 166, 152] if SMOKE_TEST else all_location_ids\n",
    "\n",
    "# Display what data will be used.\n",
    "s3_files = s3_files[starting_idx:]\n",
    "print(f\"NYC Taxi using {len(s3_files)} file(s)!\")\n",
    "print(f\"s3_files: {s3_files}\")\n",
    "print(f\"Locations: {sample_locations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf5b850-fa35-4397-bea6-b8c21fd754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a pyarrow.Table object using pyarrow parquet \n",
    "def read_data(file: str, sample_id: np.int32) -> pd.DataFrame:\n",
    "    \n",
    "    df = pq.read_table(\n",
    "        file,\n",
    "        filters=[\n",
    "            (\"passenger_count\", \">\", 0),\n",
    "            (\"trip_distance\", \">\", 0),\n",
    "            (\"fare_amount\", \">\", 0),\n",
    "            (\"pickup_location_id\", \"in\", [264, 265]),\n",
    "            (\"dropoff_location_id\", \"not in\", [264, 265]), \n",
    "            (\"dropoff_location_id\", \"=\", sample_id)\n",
    "        ],\n",
    "        columns=[\n",
    "            \"pickup_at\",\n",
    "            \"dropoff_at\",\n",
    "            \"pickup_location_id\",\n",
    "            \"dropoff_location_id\",\n",
    "            \"passenger_count\",\n",
    "            \"trip_distance\",\n",
    "            \"fare_amount\",\n",
    "        ],\n",
    "    ).to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to transform a pandas dataframe\n",
    "def transform_df(the_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = the_df.copy()\n",
    "    \n",
    "    df[\"trip_duration\"] = (df[\"dropoff_at\"] - df[\"pickup_at\"]).dt.seconds\n",
    "    df = df[df[\"trip_duration\"] > 60]\n",
    "    df = df[df[\"trip_duration\"] < 24 * 60 * 60] \n",
    "    df.drop([\"dropoff_at\", \"pickup_at\", \"pickup_location_id\", \"fare_amount\"]\n",
    "            , axis=1, inplace=True)\n",
    "    df[\"dropoff_location_id\"] = df[\"dropoff_location_id\"].fillna(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72369cbf-e346-441c-b7e3-9280ccabc7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define your Ray Tune Search Space and Search Algorithm <a class=\"anchor\" id=\"define_search_space\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310b13e-ba83-4c47-84e6-d1e916483b2b",
   "metadata": {},
   "source": [
    "**First, define a search space of experiment to run.** \n",
    "> The search space together with a search algorithm determine which experiments will be run.  \n",
    "\n",
    "Common search algorithms include grid search, random search, Bayesian search, Hyperopt, and Optuna.  For more details, see [Working with Tune Search Spaces](https://docs.ray.io/en/master/tune/tutorials/tune-search-spaces.html#tune-search-space-tutorial).  Deciding the best combination of search space and search algorithm is part of the art of being a Data Scientist and depends on the data, algorithm, and problem being solved!  \n",
    "\n",
    "**Below, we define our search space is:**\n",
    "- 2 different Scikit-learn algorithms \n",
    "- Some or all NYC taxi drop-off locations. \n",
    "\n",
    "**And we define the search algorithm is:**\n",
    "- Grid search.\n",
    "\n",
    "> This means every permutation of each algorithm and each NYC Taxi drop-off location will be a separate experiment!  \n",
    "\n",
    "Ray Tune partitions the Search space using the specified Search algorithm and takes care of running a Tune job on each partition in parallel.  Specifically, Ray Tune will pass a config dictionary to each partition and make a Trainable function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de03814-4eec-4363-a623-790f040b99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define a search space.\n",
    "sample_locations = [145, 166, 152] if SMOKE_TEST else all_location_ids\n",
    "search_space = {\n",
    "    \"model\": tune.grid_search([LinearRegression(fit_intercept=True), \n",
    "                                DecisionTreeRegressor(max_depth=3)]),\n",
    "    \"location\": tune.grid_search(sample_locations),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28814e79-f53e-4527-a959-e952f7d57fe5",
   "metadata": {},
   "source": [
    "## Define a Trainable (callable) function <a class=\"anchor\" id=\"define_trainable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3c9a4-b2df-4063-8c04-f5e0136c90bf",
   "metadata": {},
   "source": [
    "ðŸ§ª Typically when you are running Data Science experiments, you want to be able to keep track of summary metrics for each experiment, so you can decide at the end which experiments were the best.  That way, you can decide which model to deploy.\n",
    "\n",
    "ðŸ“‹ Ray Tune produces an experiments Summary table with metrics which you specify inside a \"Trainable\" or \"callable\" function.\n",
    "\n",
    "<b>Define a \"Trainable\" object that can be called from every parallel Tune experiment.</b> \n",
    ">Ray Tune has two ways of defining a trainable, namely the [Function API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs) and the Class API. Both are valid ways of defining a trainable, but *the Function API is generally recommended*.\n",
    "\n",
    "**In the cell below, we define a \"Trainable\" function called `train_model()`**.  \n",
    "- It takes as input a config dictionary argument. \n",
    "- The output can be a simple dictionary of metrics which will be reported back to the Tune Summary table.  In our case, we've chosen to force a checkpoint save of each model in addition to each experiment's metrics.\n",
    "- `train_model()` will be called in parallel by Tune for each partition of the Tune search space.  \n",
    "- Since we are using **grid search**, this means `train_model()` will be run *in parallel for every permutation* in the Tune search space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03c0ff8-0c42-4703-91f4-57fc0df8f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a custom train function\n",
    "def train_model(config: dict):\n",
    "\n",
    "    model = config['model']\n",
    "    the_location = config['location']\n",
    "    \n",
    "    # Load data.\n",
    "    df_list = [read_data(f, the_location) for f in s3_files]   \n",
    "    df_raw = pd.concat(df_list, ignore_index=True)\n",
    "    df = transform_df(df_raw)\n",
    "    \n",
    "    # Train/valid split.\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "    train_X = train_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    train_y = train_df.trip_duration\n",
    "    valid_X = valid_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    valid_y = valid_df.trip_duration\n",
    "\n",
    "    # Train model.\n",
    "    model = model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(valid_X)\n",
    "    \n",
    "    # Evaluate.\n",
    "    error = sklearn.metrics.mean_absolute_error(valid_y, pred_y)\n",
    "    \n",
    "    # Save the model as a Tune Checkpoint.  \n",
    "    # This is done through ray.air.session.report() API.\n",
    "    # https://docs.ray.io/en/latest/tune/tutorials/tune-checkpoints.html\n",
    "    \n",
    "    # Define a model checkpoint.\n",
    "    checkpoint = SklearnCheckpoint.from_estimator(model, path=\".\")\n",
    "\n",
    "    # Save checkpoint and report back metrics, using ray.air.session.report()\n",
    "    metrics = dict(error = error)\n",
    "    session.report(\n",
    "            metrics, \n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb435c-8485-4146-9e22-cff77b3f4946",
   "metadata": {},
   "source": [
    "## Run independent experiments in Parallel using Ray Tune <a class=\"anchor\" id=\"run_tune_search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d0d25-a5b0-4887-9d1a-a775d0107d12",
   "metadata": {},
   "source": [
    "Now we are ready to use Ray Tune to run separate, parallel training jobs, each as a different experiment, per dropoff location.\n",
    "\n",
    "**Configure the resources allocated per experiment (trial).** Tune uses this resources allocation to control the parallelism. For example, if each trial was configured to use 4 CPUs, and the cluster had only 32 CPUs, then Tune will limit the number of concurrent trials to 8 to avoid overloading the cluster. For more information, see [A Guide To Parallelism and Resources](https://docs.ray.io/en/master/tune/tutorials/tune-resources.html#tune-parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa9df92-a412-42a8-b833-98dc86d58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Can customize resources per experiment, here we set 1 CPU each.\n",
    "train_model = tune.with_resources(train_model, {\"cpu\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36ca20-54ad-4400-88fe-ca8cc7ffbf84",
   "metadata": {},
   "source": [
    "**Below, we introduce AIR configs and run the experiment using `tuner.fit()`.** Tune will report on experiment status, and after the experiment finishes, you can inspect the results. \n",
    "\n",
    "Notice in the AIR config, we have specified a local directory `my_Tune_logs` for logging instead of the default `~/ray_results` directory. Learn more about logging Tune results at [How to configure logging in Tune](https://docs.ray.io/en/master/tune/tutorials/tune-output.html#tune-logging).\n",
    "\n",
    "Tune can [retry failed experiments automatically](https://docs.ray.io/en/master/tune/tutorials/tune-stopping.html#tune-stopping-guide), as well as entire experiments.  This is necessary in case a node on your remote cluster fails (when running on a cloud such as AWS or GCP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670d4015-4b0e-4a1a-88d7-07ac4a4e2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:17:51,926\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-09 11:21:05 (running for 00:03:12.58)<br>Memory usage on this node: 12.9/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.05 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/christy/Documents/github_ray_temp/ray/doc/source/ray-air/examples/my_Tune_logs/batch_tuning<br>Number of trials: 6/6 (6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  location</th><th>model               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_34a03_00000</td><td>TERMINATED</td><td>127.0.0.1:27533</td><td style=\"text-align: right;\">       145</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         188.856</td><td style=\"text-align: right;\">561.359</td></tr>\n",
       "<tr><td>train_model_34a03_00001</td><td>TERMINATED</td><td>127.0.0.1:27541</td><td style=\"text-align: right;\">       166</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         185.675</td><td style=\"text-align: right;\">392.353</td></tr>\n",
       "<tr><td>train_model_34a03_00002</td><td>TERMINATED</td><td>127.0.0.1:27542</td><td style=\"text-align: right;\">       152</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         188.982</td><td style=\"text-align: right;\">281.491</td></tr>\n",
       "<tr><td>train_model_34a03_00003</td><td>TERMINATED</td><td>127.0.0.1:27543</td><td style=\"text-align: right;\">       145</td><td>DecisionTreeReg_64f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         154.691</td><td style=\"text-align: right;\">212.417</td></tr>\n",
       "<tr><td>train_model_34a03_00004</td><td>TERMINATED</td><td>127.0.0.1:27544</td><td style=\"text-align: right;\">       166</td><td>DecisionTreeReg_6670</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         186.074</td><td style=\"text-align: right;\">272.838</td></tr>\n",
       "<tr><td>train_model_34a03_00005</td><td>TERMINATED</td><td>127.0.0.1:27545</td><td style=\"text-align: right;\">       152</td><td>DecisionTreeReg_67f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         177.048</td><td style=\"text-align: right;\">645.461</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:20:30,968\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00003 reported error=212.41666666666666,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 145}.\n",
      "Trial train_model_34a03_00003 completed. Last result: error=212.41666666666666,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:20:53,331\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00005 reported error=645.4611111111111,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 152}.\n",
      "Trial train_model_34a03_00005 completed. Last result: error=645.4611111111111,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:21:01,940\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00001 reported error=392.3529239230686,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 166}.\n",
      "Trial train_model_34a03_00001 completed. Last result: error=392.3529239230686,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:21:02,301\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00004 reported error=272.8375661375661,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 166}.\n",
      "Trial train_model_34a03_00004 completed. Last result: error=272.8375661375661,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:21:03,143\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00000 reported error=561.3589579264323,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 145}.\n",
      "Trial train_model_34a03_00000 completed. Last result: error=561.3589579264323,should_checkpoint=True\n",
      "Trial train_model_34a03_00002 reported error=281.4914916992187,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 152}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:21:05,128\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_34a03_00002 completed. Last result: error=281.4914916992187,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 11:21:05,255\tINFO tune.py:758 -- Total run time: 193.33 seconds (192.58 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 6\n",
      "TOTAL TIME TAKEN: 193.36 seconds\n",
      "Best result: {'model': DecisionTreeRegressor(max_depth=3), 'location': 145}\n"
     ]
    }
   ],
   "source": [
    "# Define a tuner object using Ray AIR Tuner API\n",
    "tuner = tune.Tuner(\n",
    "    train_model, \n",
    "    param_space=search_space,\n",
    "    run_config=air.RunConfig(\n",
    "        \n",
    "        #redirect logs to relative path instead of default ~/ray_results/\n",
    "        local_dir = \"my_Tune_logs\",\n",
    "        name = \"batch_tuning\",\n",
    "\n",
    "        # Set Ray Tune verbosity.  Print summary table only with levels 2 or 3.\n",
    "        verbose=2,\n",
    "        ),\n",
    ")\n",
    "\n",
    "# 4. Run the experiments with Ray Tune\n",
    "start = time.time()\n",
    "results = tuner.fit()\n",
    "total_time_taken = time.time() - start\n",
    "\n",
    "# Assemble Tune results into a pandas dataframe\n",
    "results_df = results.get_dataframe()\n",
    "\n",
    "# Print some training stats\n",
    "print(f\"Total number of models: {results_df.shape[0]}\")\n",
    "print(f\"TOTAL TIME TAKEN: {total_time_taken:.2f} seconds\")\n",
    "best_result = results.get_best_result(metric=\"error\", mode=\"min\").config\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af943052-bd4b-421b-bc89-c62ed5f65e57",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>After all the Tune experiments have run, pick the best model per dropoff location. </b>\n",
    "\n",
    "We can assemble the Tune results ([ResultGrid object](https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html)) into a pandas dataframe, then sort by minimum error, to select the best model per dropoff location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997f71f2-3ded-48d6-b52d-d4eef0719e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['error', 'time_this_iter_s', 'should_checkpoint', 'done',\n",
      "       'timesteps_total', 'episodes_total', 'training_iteration', 'trial_id',\n",
      "       'experiment_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname',\n",
      "       'node_ip', 'time_since_restore', 'timesteps_since_restore',\n",
      "       'iterations_since_restore', 'warmup_time', 'config/location',\n",
      "       'config/model', 'logdir'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>LinearRegression()</th>\n",
       "      <td>561.358958</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <th>LinearRegression()</th>\n",
       "      <td>392.352924</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <th>LinearRegression()</th>\n",
       "      <td>281.491492</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>DecisionTreeRegressor(max_depth=3)</th>\n",
       "      <td>212.416667</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <th>DecisionTreeRegressor(max_depth=3)</th>\n",
       "      <td>272.837566</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     error  \\\n",
       "location_id model_name                                       \n",
       "145         LinearRegression()                  561.358958   \n",
       "166         LinearRegression()                  392.352924   \n",
       "152         LinearRegression()                  281.491492   \n",
       "145         DecisionTreeRegressor(max_depth=3)  212.416667   \n",
       "166         DecisionTreeRegressor(max_depth=3)  272.837566   \n",
       "\n",
       "                                                                                           logdir  \n",
       "location_id model_name                                                                             \n",
       "145         LinearRegression()                  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "166         LinearRegression()                  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "152         LinearRegression()                  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "145         DecisionTreeRegressor(max_depth=3)  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "166         DecisionTreeRegressor(max_depth=3)  /Users/christy/Documents/github_ray_temp/ray/d...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble Tune results into a pandas dataframe\n",
    "print(results_df.columns)\n",
    "results_df = results_df[[\"config/location\", \"config/model\", \"error\", \"logdir\"]]\n",
    "results_df.rename(columns={'config/location':'location_id'}, inplace=True)\n",
    "results_df.rename(columns={'config/model':'model_name'}, inplace=True)\n",
    "results_df.set_index([\"location_id\", \"model_name\"], inplace=True)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "612b4bc3-72e4-478f-b59c-83c78ebd7900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id      int64\n",
      "model_name      object\n",
      "error          float64\n",
      "logdir          object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>error</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>DecisionTreeRegressor(max_depth=3)</td>\n",
       "      <td>212.416667</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>DecisionTreeRegressor(max_depth=3)</td>\n",
       "      <td>272.837566</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>281.491492</td>\n",
       "      <td>/Users/christy/Documents/github_ray_temp/ray/d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id                          model_name       error  \\\n",
       "0          145  DecisionTreeRegressor(max_depth=3)  212.416667   \n",
       "1          166  DecisionTreeRegressor(max_depth=3)  272.837566   \n",
       "2          152                  LinearRegression()  281.491492   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "1  /Users/christy/Documents/github_ray_temp/ray/d...  \n",
       "2  /Users/christy/Documents/github_ray_temp/ray/d...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 1 model per location_id with minimum error\n",
    "final_df = results_df.reset_index()\n",
    "final_df = final_df.loc[final_df.groupby('location_id')['error'].idxmin()].copy()\n",
    "final_df.sort_values(by=[\"error\"], inplace=True)\n",
    "final_df.reset_index(inplace=True, drop=True)\n",
    "print(final_df.dtypes)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4554830-1546-4353-a41e-621bdf46aeab",
   "metadata": {},
   "source": [
    "## Load a model from checkpoint and perform inference  <a class=\"anchor\" id=\"load_checkpoint\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b218d5-3e64-4b1d-9ad7-5ae3c8a8a78d",
   "metadata": {},
   "source": [
    "> **[Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) make batch inference easy since they have internal logic to parallelize the inference.**\n",
    "\n",
    "However, in this notebook, we will just restore a single scikit-learn model directly from checkpoint, and demonstrate it can be used for inference.  \n",
    "\n",
    "Users can easily obtain checkpoint objects from the Tune results object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f5c78fa-38a9-4e8c-bddc-ffbb45aa2d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christy/Documents/github_ray_temp/ray/doc/source/ray-air/examples/my_Tune_logs/batch_tuning/train_model_34a03_00003_3_location=145,model=DecisionTreeRegressor_max_depth_3_2022-11-09_11-17-54/checkpoint_000000\n",
      "<class 'ray.train.sklearn.sklearn_checkpoint.SklearnCheckpoint'>\n",
      "<class 'sklearn.tree._classes.DecisionTreeRegressor'>\n"
     ]
    }
   ],
   "source": [
    "# Get a checkpoint path from Ray Tune results. \n",
    "checkpoint_path = final_df.logdir[0] + \"/checkpoint_000000\"\n",
    "print(checkpoint_path)\n",
    "\n",
    "# Recover SklearnCheckpoint object from path\n",
    "checkpoint = SklearnCheckpoint.from_directory(checkpoint_path)\n",
    "print(type(checkpoint))\n",
    "\n",
    "# Restore a model from checkpoint\n",
    "model = checkpoint.get_estimator()\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a29cd1d1-68f1-4c79-ad87-51b1a01aacc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dropoff location\n",
    "the_location = final_df.location_id[0]\n",
    "the_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb844fc1-2ae3-43dd-8737-5f8b7d0cbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test data\n",
    "df_list = [read_data(f, the_location) for f in s3_files[:1]]   \n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "df = transform_df(df_raw)\n",
    "\n",
    "# Train/test split.\n",
    "_, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "test_X = test_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "test_y = np.array(test_df.trip_duration)  #actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35ffd80-a5ed-4eb0-9bb0-bc5774aa2c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_y</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1272.750000</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370.000000</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2671.500000</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1272.750000</td>\n",
       "      <td>1813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>866.333333</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>666.000000</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_y  trip_duration\n",
       "0  1272.750000           1496\n",
       "1   370.000000            427\n",
       "2  2671.500000           1918\n",
       "3  1272.750000           1813\n",
       "4   866.333333           1015\n",
       "5   666.000000            649"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference using restored model from checkpoint\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# Zip together to visualize\n",
    "pd.DataFrame(zip(pred_y, test_y), \n",
    "             columns = [\"pred_y\", \"trip_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde96350-e13d-4c37-9acb-50e2f3a0f48e",
   "metadata": {},
   "source": [
    "<b>Compare validation and test error.</b>\n",
    "\n",
    "During model training we reported error on \"validation\" data (random sample).  Below, we will report error on a pretend \"test\" data set (a different random sample).\n",
    "\n",
    "Do a quick validation that both errors are reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243a7f6c-3d74-42c1-b2d4-caba0cfa1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 289.9444444444444\n"
     ]
    }
   ],
   "source": [
    "# Evaluate.\n",
    "error = sklearn.metrics.mean_absolute_error(test_y, pred_y)\n",
    "print(f\"Test error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526709cc-be4c-4cbf-99c0-ee10a916ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 212.41666666666663\n"
     ]
    }
   ],
   "source": [
    "# Compare test error with validation error\n",
    "print(f\"Train error: {final_df.error[0]}\")\n",
    "\n",
    "# Validation and test errors should be reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e586-a6b2-4c30-b627-8e50c9a525a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
